version: '3.8'

services:
  litellm:
    env_file: .env
    image: ghcr.io/berriai/litellm:main-latest
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    environment:
      - DATABASE_URL=""
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION_NAME=${AWS_REGION_NAME}
    ports:
      - '4000:4000'
    command: --config /app/config.yaml --detailed_debug
    restart: unless-stopped

  openwebui:
    env_file: .env
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - open-webui:/app/backend/data
    environment:
      - WEBUI_NAME=${WEBUI_NAME}
      - WEBUI_URL=${WEBUI_URL}
      - WEBUI_AUTH=${WEBUI_AUTH}
      - ENABLE_COMMUNITY_SHARING=${ENABLE_COMMUNITY_SHARING}
      - ENABLE_MESSAGE_RATING=${ENABLE_MESSAGE_RATING}
      - ENABLE_OLLAMA_API=${ENABLE_OLLAMA_API}
      - ENABLE_OPENAI_API=${ENABLE_OPENAI_API}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SCARF_NO_ANALYTICS=${SCARF_NO_ANALYTICS}
      - DO_NOT_TRACK=${DO_NOT_TRACK}
      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY}
    ports:
      - '${OPEN_WEBUI_PORT-3000}:8080'
    depends_on:
      - litellm
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  litellm: {}
  open-webui: {}
