# Ollama URL for the backend to connect
# The path '/ollama' will be redirected to the specified backend URL
# OLLAMA_BASE_URL='http://localhost:11434'


# openwebui -----------------------------------------------------------------------------------------------------------

# general
WEBUI_NAME="Utopia"
WEBUI_URL="http://77.37.96.94:3000"
WEBUI_AUTH=True
DEFAULT_MODELS="Meta-Llama-3.1-70B-Instruct"
DEFAULT_USER_ROLE="pending"
USER_PERMISSIONS_CHAT_DELETION=False
ENABLE_COMMUNITY_SHARING=False
ENABLE_MESSAGE_RATING=True
DATABASE_URL="postgresql://postgres:postgres@host.docker.internal:54322/postgres"

# ollama
ENABLE_OLLAMA_API=False

# openai
ENABLE_OPENAI_API=True
OPENAI_API_BASE_URL="http://host.docker.internal:4000/v1"
OPENAI_API_KEY="anything"

# AUTOMATIC1111_BASE_URL="http://localhost:7860"

# telemetry
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false

# litellm -----------------------------------------------------------------------------------------------------------
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION_NAME=
